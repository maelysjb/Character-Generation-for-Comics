{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![bse_logo_textminingcourse](https://bse.eu/sites/default/files/bse_logo_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Model: LoRA Inference\n",
    "\n",
    "The following code is for the inference part of the LoRA model. The model training can be found in the notebook \"LoRA.ipynb\" in section 4. Fine Tuning Models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages and Install Diffusion libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffuser libraries \n",
    "\n",
    "!pip install -qq \"ipywidgets>=7,<8\"\n",
    "!git clone https://github.com/huggingface/diffusers\n",
    "!pip install ./diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /kaggle/working/diffusers/examples/text_to_image\n",
    "!pip install -r requirements.txt\n",
    "!pip install bitsandbytes\n",
    "!pip install transformers gradio ftfy accelerate\n",
    "!pip install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training \n",
    "from diffusers import DiffusionPipeline, UNet2DConditionModel\n",
    "from transformers import CLIPTextModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace \"TOKEN\" with own personal Hugging Face token in order to save model in a private model and dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"TOKEN\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instructions on how to set up the secret token on Kaggle: https://github.com/maelysjb/Comics-GenAI/blob/main/README.md#:~:text=.gitignore-,README,-.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "secret_label = \"HUGGINGFACE_TOKEN\"\n",
    "secret_value = UserSecretsClient().get_secret(secret_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the trained model \n",
    "Replace the base model path with the desired Hugging Face repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import AutoPipelineForText2Image\n",
    "import torch\n",
    "\n",
    "# Define the base Hugging Face repository path\n",
    "base_model_path = 'nataliabeltran/LoRA600' \n",
    "\n",
    "## Pipeline \n",
    "pipeline = AutoPipelineForText2Image.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16).to(\"cuda\")\n",
    "pipeline.load_lora_weights(base_model_path, weight_name=\"pytorch_lora_weights.safetensors\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "def inference(prompt, num_samples, negative_prompt, guidance_scale,\n",
    "              num_inference_steps, height, width):\n",
    "    images = pipeline(\n",
    "        prompt,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        negative_prompt=negative_prompt,\n",
    "        num_images_per_prompt=num_samples,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        guidance_scale=guidance_scale\n",
    "    ).images\n",
    "    for i, image in enumerate(images):\n",
    "        image.save(f\"generated_image_{i}.png\")  \n",
    "        print(f\"Generated image {i}:\")\n",
    "        display(image)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display outputs from LoRA model\n",
    "To generate different images of the character/data change the prompt ensuring to keep the same phrasing that was used while training. \n",
    "\n",
    "More images at different training steps for the different models can be found here: https://github.com/maelysjb/Comics-GenAI/tree/main/6.%20Generated%20Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Display\n",
    "from IPython.display import display  \n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"An image of UnicornGirl in unicorn onesie playing tennis\"\n",
    "num_samples = 5\n",
    "negative_prompt = \"\"\n",
    "guidance_scale = 7.5\n",
    "num_inference_steps = 50\n",
    "height = 512\n",
    "width = 512\n",
    "\n",
    "inference(prompt, num_samples, negative_prompt, guidance_scale, num_inference_steps, height, width)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
