{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![bse_logo_textminingcourse](https://bse.eu/sites/default/files/bse_logo_small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Model: DreamBooth\n",
    "\n",
    "We implemented a Stable Diffusion model using the DreamBooth method, which is a text-to-image generation technique designed to work with a small number of data points, as in our project. DreamBooth trains and updates the full diffusion model using these limited images and associated prompts. This method allows the model to recognize specific images by associating them with a unique concept or word provided in the prompt.\n",
    "\n",
    "\n",
    "The code was adapted by our team based on the following source code:\n",
    "- Uysal, E. (2024, January 13). *Fine-Tuning Stable Diffusion with DreamBooth Method*. https://enessadi.medium.com/fine-tuning-stable-diffusion-with-dreambooth-method-52019b3599dd\n",
    "\n",
    "We ran this code in Kaggle but there is also a different version that is set up to run on Google Colab named \"DreamBooth_GoogleColab.ipynb\" found in section 4. Fine Tuning Models of our github. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Environment \n",
    "\n",
    "For instructions on how to set up the GPU for kaggle, please see the following link: https://github.com/maelysjb/Comics-GenAI/blob/main/README.md#:~:text=.gitignore-,README,-.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages and Install Diffusion libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffuser libraries \n",
    "\n",
    "!pip install -qq \"ipywidgets>=7,<8\"\n",
    "!git clone https://github.com/huggingface/diffusers\n",
    "!pip install ./diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DreamBooth requirements & xFormers Library \n",
    "\n",
    "%cd /kaggle/working/diffusers/examples/dreambooth\n",
    "!pip install -r requirements.txt\n",
    "!pip install bitsandbytes\n",
    "!pip install transformers gradio ftfy accelerate\n",
    "!pip install xformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Image Display\n",
    "from PIL import Image\n",
    "import IPython.display as display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training \n",
    "from diffusers import DiffusionPipeline, UNet2DConditionModel\n",
    "from transformers import CLIPTextModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face \n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder for datasets \n",
    "# Kaggle \n",
    "%cd /kaggle/working\n",
    "\n",
    "if os.path.exists(\"/kaggle/working/custom_dataset\"):\n",
    "    print(\"Removing existing custom_dataset folder\")\n",
    "    !rm -rf /kaggle/working/custom_dataset\n",
    "\n",
    "print(\"Creating new custom_dataset folder\")\n",
    "!mkdir /kaggle/working/custom_dataset\n",
    "!mkdir /kaggle/working/custom_dataset/class_images\n",
    "!mkdir /kaggle/working/custom_dataset/instance_images\n",
    "\n",
    "print('Custom Dataset folder is created: /kaggle/working/custom_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically adding the data to the folders for Kaggle \n",
    "\n",
    "input_path = '/kaggle/input/unicorngirl/personnage'\n",
    "output_path = '/kaggle/working/custom_dataset/instance_images'\n",
    "\n",
    "files = os.listdir(input_path)\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "for file in files:\n",
    "    src = os.path.join(input_path, file)\n",
    "    dst = os.path.join(output_path, file)\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "print(\"Images copied successfully to the output directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data size function \n",
    "\n",
    "def resize_and_crop_images(folder_path, target_size=512):\n",
    "    \"\"\"\n",
    "    Resize the images in a folder to have a smaller edge of the specified target size and save them to a new location.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): Path to the folder containing the images.\n",
    "    - target_size (int): Desired size for the smaller edge (default is 512).\n",
    "    \"\"\"\n",
    "    # Define the output folder for resized and cropped images\n",
    "    output_folder = '/kaggle/working/resized_images'\n",
    "    \n",
    "    # Create the output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Iterate through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # Check if the file is an image\n",
    "        if os.path.isfile(file_path) and filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "            # Open the image\n",
    "            image = Image.open(file_path)\n",
    "\n",
    "            # Get the original width and height\n",
    "            width, height = image.size\n",
    "\n",
    "            # Calculate the new size while maintaining the aspect ratio\n",
    "            if width <= height:\n",
    "                new_width = target_size\n",
    "                new_height = int(height * (target_size / width))\n",
    "            else:\n",
    "                new_width = int(width * (target_size / height))\n",
    "                new_height = target_size\n",
    "\n",
    "            # Resize the image\n",
    "            resized_image = image.resize((new_width, new_height))\n",
    "\n",
    "            left = (new_width - target_size) // 2\n",
    "            top = (new_height - target_size) // 2\n",
    "            right = (new_width + target_size) // 2\n",
    "            bottom = (new_height + target_size) // 2\n",
    "\n",
    "            # Perform the center crop\n",
    "            cropped_image = resized_image.crop((left, top, right, bottom))\n",
    "            \n",
    "            # Save the cropped image to the output folder\n",
    "            cropped_image.save(os.path.join(output_folder, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting images function \n",
    "\n",
    "def show_images_in_one_row(folder_path, target_size=256):\n",
    "    images = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path) and filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((target_size, int(target_size * img.size[1] / img.size[0])))\n",
    "            images.append(img)\n",
    "\n",
    "    # Display images in one row\n",
    "    fig, axes = plt.subplots(1, len(images), figsize=(len(images) * 3, 3))\n",
    "    for ax, img in zip(axes, images):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Images\n",
    "folder_path = '/kaggle/working/custom_dataset/class_images'\n",
    "if len(os.listdir(folder_path)):\n",
    "  resize_and_crop_images(folder_path)\n",
    "  show_images_in_one_row(folder_path)\n",
    "\n",
    "# Instance Images\n",
    "folder_path_img = '/kaggle/working/custom_dataset/instance_images'\n",
    "resize_and_crop_images(folder_path_img)\n",
    "show_images_in_one_row(folder_path_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder for the generated images \n",
    "output_folder = '/kaggle/working/outputs'\n",
    "\n",
    "if os.path.exists(output_folder):\n",
    "    print(\"Removing existing outputs folder\")\n",
    "    !rm -rf $output_folder\n",
    "\n",
    "print(\"Creating new outputs folder\")\n",
    "!mkdir $output_folder\n",
    "\n",
    "print('Output folder is created:', output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Login into Hugging Face account \n",
    "\n",
    "Replace the name for the Hugging Face token where it states: \"TOKEN_FROM_HF\" to the desired name. This will be your own personal Hugging Gace token in order to save a private model and dataset. \n",
    "\n",
    "Instructions on using Hugging Face can be found here: https://github.com/maelysjb/Comics-GenAI/blob/main/README.md#:~:text=.gitignore-,README,-.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login(token=\"TOKEN_FROM_HF\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training DreamBooth Diffusion model\n",
    "Replace the name for the Hugging Face model id where it states: \"DreamBooth200\" to the desired name. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /kaggle/working/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
    "    --pretrained_model_name_or_path 'runwayml/stable-diffusion-v1-5' \\\n",
    "    --revision \"fp16\" \\\n",
    "    --instance_data_dir '/kaggle/working/custom_dataset/instance_images' \\\n",
    "    --class_data_dir '/kaggle/working/custom_dataset/class_images' \\\n",
    "    --instance_prompt 'An image of UnicornGirl in unicorn onesie.' \\\n",
    "    --class_prompt 'An image of UnicornGirl in a unicorn onesie.' \\\n",
    "    --with_prior_preservation \\\n",
    "    --prior_loss_weight 1.0 \\\n",
    "    --num_class_images 50 \\\n",
    "    --output_dir '/kaggle/working/outputs' \\\n",
    "    --resolution 512 \\\n",
    "    --train_text_encoder \\\n",
    "    --train_batch_size 2 \\\n",
    "    --sample_batch_size 2 \\\n",
    "    --max_train_steps 2000 \\\n",
    "    --checkpointing_steps 1850 \\\n",
    "    --gradient_accumulation_steps 1 \\\n",
    "    --gradient_checkpointing \\\n",
    "    --learning_rate 1e-6 \\\n",
    "    --lr_scheduler 'constant' \\\n",
    "    --lr_warmup_steps=0 \\\n",
    "    --use_8bit_adam \\\n",
    "    --validation_prompt 'An image of UnicornGirl in a unicorn onesie.' \\\n",
    "    --num_validation_images 4 \\\n",
    "    --mixed_precision \"fp16\" \\\n",
    "    --enable_xformers_memory_efficient_attention \\\n",
    "    --set_grads_to_none \\\n",
    "    --push_to_hub \\\n",
    "    --hub_model_id DreamBooth2000 \n",
    "    #--report_to 'wandb'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
