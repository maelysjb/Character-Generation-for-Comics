'NoneType' object has no attribute 'cadam32bit_grad_fp32'
> INFO    Namespace(version=False, revision=None, tokenizer=None, image_path='/Users/arimichelangelo/Master-thesis/Comics-GenAI/data', class_image_path=None, prompt='An image of Piglet', class_prompt=None, num_class_images=100, class_labels_conditioning=None, prior_preservation=None, prior_loss_weight=1.0, resolution=1024, center_crop=None, train_text_encoder=None, sample_batch_size=4, num_steps=5, checkpointing_steps=100000, resume_from_checkpoint=None, scale_lr=None, scheduler='constant', warmup_steps=0, num_cycles=1, lr_power=1.0, dataloader_num_workers=0, use_8bit_adam=None, adam_beta1=0.9, adam_beta2=0.999, adam_weight_decay=0.01, adam_epsilon=1e-08, max_grad_norm=1.0, allow_tf32=None, prior_generation_precision=None, local_rank=-1, xformers=None, pre_compute_text_embeddings=None, tokenizer_max_length=None, text_encoder_use_attention_mask=None, rank=4, xl=None, mixed_precision='no', validation_prompt=None, num_validation_images=4, validation_epochs=50, checkpoints_total_limit=None, validation_images=None, logging=None, train=None, deploy=None, inference=None, username=None, backend='local-cli', token='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', repo_id='maelysjb/sdxl-lora-piglet', push_to_hub=True, model='stabilityai/stable-diffusion-xl-base-1.0', project_name='Dreambooth-SDXL', seed=42, epochs=1, gradient_accumulation=1, disable_gradient_checkpointing=None, lr=0.0001, log='none', data_path=None, train_split='train', valid_split=None, batch_size=1, func=<function run_dreambooth_command_factory at 0x174be17e0>)
> INFO    Running DreamBooth Training
> WARNING Parameters not supplied by user and set to default: vae_model
> WARNING Parameters supplied but not used: backend, version, train, inference, log, data_path, deploy, func, train_split, valid_split
> INFO    Dataset: Dreambooth-SDXL (dreambooth)

> INFO    Saving concept images
> INFO    /Users/arimichelangelo/Master-thesis/Comics-GenAI/data/download-3.jpg
> INFO    Saving concept images
> INFO    /Users/arimichelangelo/Master-thesis/Comics-GenAI/data/download-2.jpg
> INFO    Saving concept images
> INFO    /Users/arimichelangelo/Master-thesis/Comics-GenAI/data/download-1.jpg
> INFO    Saving concept images
> INFO    /Users/arimichelangelo/Master-thesis/Comics-GenAI/data/download-5.jpg
> INFO    Saving concept images
> INFO    /Users/arimichelangelo/Master-thesis/Comics-GenAI/data/download-4.jpg
> INFO    Starting local training...
> INFO    {"model":"stabilityai/stable-diffusion-xl-base-1.0","vae_model":null,"revision":null,"tokenizer":null,"image_path":"Dreambooth-SDXL/autotrain-data","class_image_path":null,"prompt":"An image of Piglet","class_prompt":null,"num_class_images":100,"class_labels_conditioning":null,"prior_preservation":false,"prior_loss_weight":1.0,"project_name":"Dreambooth-SDXL","seed":42,"resolution":1024,"center_crop":false,"train_text_encoder":false,"batch_size":1,"sample_batch_size":4,"epochs":1,"num_steps":5,"checkpointing_steps":100000,"resume_from_checkpoint":null,"gradient_accumulation":1,"disable_gradient_checkpointing":false,"lr":0.0001,"scale_lr":false,"scheduler":"constant","warmup_steps":0,"num_cycles":1,"lr_power":1.0,"dataloader_num_workers":0,"use_8bit_adam":false,"adam_beta1":0.9,"adam_beta2":0.999,"adam_weight_decay":0.01,"adam_epsilon":1e-8,"max_grad_norm":1.0,"allow_tf32":false,"prior_generation_precision":null,"local_rank":-1,"xformers":false,"pre_compute_text_embeddings":false,"tokenizer_max_length":null,"text_encoder_use_attention_mask":false,"rank":4,"xl":true,"mixed_precision":"no","token":"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","repo_id":"maelysjb/sdxl-lora-piglet","push_to_hub":true,"username":null,"validation_prompt":null,"num_validation_images":4,"validation_epochs":50,"checkpoints_total_limit":null,"validation_images":null,"logging":false}
> INFO    ['python', '-m', 'autotrain.trainers.dreambooth', '--training_config', 'Dreambooth-SDXL/training_params.json']
/Users/arimichelangelo/anaconda3/envs/autotrain/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  torch.utils._pytree._register_pytree_node(
/Users/arimichelangelo/anaconda3/envs/autotrain/lib/python3.10/site-packages/diffusers/utils/outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  torch.utils._pytree._register_pytree_node(
You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.
{'clip_sample_range', 'thresholding', 'rescale_betas_zero_snr', 'variance_type', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.
{'attention_type', 'dropout', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.
/Users/arimichelangelo/anaconda3/envs/autotrain/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.
  warn("The installed version of bitsandbytes was compiled without GPU support. "
ðŸš€ INFO   | 2024-04-11 18:09:31 | autotrain.trainers.dreambooth.train_xl:main:784 - ***** Running training *****
ðŸš€ INFO   | 2024-04-11 18:09:31 | autotrain.trainers.dreambooth.train_xl:main:785 -   Num examples = 5
ðŸš€ INFO   | 2024-04-11 18:09:31 | autotrain.trainers.dreambooth.train_xl:main:786 -   Num batches each epoch = 5
ðŸš€ INFO   | 2024-04-11 18:09:31 | autotrain.trainers.dreambooth.train_xl:main:787 -   Num Epochs = 1
ðŸš€ INFO   | 2024-04-11 18:09:31 | autotrain.trainers.dreambooth.train_xl:main:788 -   Instantaneous batch size per device = 1
ðŸš€ INFO   | 2024-04-11 18:09:31 | autotrain.trainers.dreambooth.train_xl:main:789 -   Total train batch size (w. parallel, distributed & accumulation) = 1
ðŸš€ INFO   | 2024-04-11 18:09:31 | autotrain.trainers.dreambooth.train_xl:main:790 -   Gradient Accumulation steps = 1
ðŸš€ INFO   | 2024-04-11 18:09:31 | autotrain.trainers.dreambooth.train_xl:main:791 -   Total optimization steps = 5
Steps:   0%|          | 0/5 [00:00<?, ?it/s]Steps:  20%|â–ˆâ–ˆ        | 1/5 [00:29<01:56, 29.16s/it]Steps:  20%|â–ˆâ–ˆ        | 1/5 [00:29<01:56, 29.16s/it, loss=0.136, lr=0.0001]Steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:04<01:37, 32.66s/it, loss=0.136, lr=0.0001]Steps:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [01:04<01:37, 32.66s/it, loss=0.00311, lr=0.0001]Steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:35<01:03, 31.91s/it, loss=0.00311, lr=0.0001]Steps:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:35<01:03, 31.91s/it, loss=0.0677, lr=0.0001] Steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:30<00:41, 41.16s/it, loss=0.0677, lr=0.0001]Steps:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [02:30<00:41, 41.16s/it, loss=0.283, lr=0.0001] Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:18<00:00, 43.65s/it, loss=0.283, lr=0.0001]Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:18<00:00, 43.65s/it, loss=0.0348, lr=0.0001]Model weights saved in Dreambooth-SDXL/pytorch_lora_weights.safetensors
{'image_encoder', 'feature_extractor'} was not found in config. Values will be initialized to default values.

Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s][ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of stabilityai/stable-diffusion-xl-base-1.0.

Loading pipeline components...:  14%|â–ˆâ–        | 1/7 [00:00<00:00,  7.98it/s][A{'sigma_min', 'timestep_type', 'rescale_betas_zero_snr', 'sigma_max'} was not found in config. Values will be initialized to default values.
Loaded scheduler as EulerDiscreteScheduler from `scheduler` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loaded tokenizer_2 as CLIPTokenizer from `tokenizer_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
Loaded text_encoder_2 as CLIPTextModelWithProjection from `text_encoder_2` subfolder of stabilityai/stable-diffusion-xl-base-1.0.

Loading pipeline components...:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 4/7 [00:00<00:00, 12.41it/s][ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of stabilityai/stable-diffusion-xl-base-1.0.
{'attention_type', 'dropout', 'reverse_transformer_layers_per_block'} was not found in config. Values will be initialized to default values.
Loaded unet as UNet2DConditionModel from `unet` subfolder of stabilityai/stable-diffusion-xl-base-1.0.

Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  8.95it/s][ALoading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00,  9.31it/s]
{'use_lu_lambdas', 'lower_order_final', 'solver_type', 'thresholding', 'euler_at_final', 'lambda_min_clipped', 'algorithm_type', 'final_sigmas_type', 'variance_type', 'solver_order', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.
Loading unet.
Steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [03:21<00:00, 40.23s/it, loss=0.0348, lr=0.0001]
